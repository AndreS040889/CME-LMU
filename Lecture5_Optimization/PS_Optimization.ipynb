{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Methods in Economics\n",
    "\n",
    "## Problem Set 3 - Numerical Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last update: 2018-02-22 14:56:37.760261\n"
     ]
    }
   ],
   "source": [
    "# Author: Alex Schmitt (schmitt@ifo.de)\n",
    "\n",
    "import datetime\n",
    "print('Last update: ' + str(datetime.datetime.today()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries\n",
    "\n",
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn\n",
    "\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import scipy.linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (N)\n",
    "\n",
    "*From Judd(1998), chapter 4, question 2*. One of the classical uses of optimization is the computation of the *Pareto frontier*. Consider the endowment economy with $m$ goods and $n$ agents. Assume that agent $i$'s utility function over the $m$ goods is \n",
    "\n",
    "\\begin{equation}\n",
    "    u^{i}(x^i) = \\sum^{m}_{j = 1} a^i_j (x^i_j)^{v^i_j + 1} (1 + v^i_j)^{-1} \n",
    "\\end{equation}\n",
    "\n",
    "Suppose that agent $i$'s endowment of good $j$ is $e^i_j$. Assume that $a^i_j, e^i_j > 0 > v^i_j$ (for $v^i_j$, we replace $(x^i_j)^{v^i_j + 1} (1 + v^i_j)^{-1}$ with $\\ln x^i_j$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Write a program using Scipy's BFGS implementation that will read in the $v^i_j$, $a^i_j$ and $e^i_j$ and the social weights $\\lambda^i$, and output the solution to the social planner's problem. Choose $m = n = 2$ and solve the problem *analytically* for $\\lambda_1 = \\lambda_2 = 0.5$ and the following values for the remaining parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V = [[-4 -2]\n",
      " [-3 -3]]\n",
      "A = [[1 4]\n",
      " [1 8]]\n",
      "E = [[6 4]\n",
      " [5 1]]\n"
     ]
    }
   ],
   "source": [
    "E = np.array([[6, 4], [5, 1]])\n",
    "V = np.array([[-4, -2], [-3, -3]])\n",
    "A = np.array([[1, 4], [1, 8]])\n",
    "\n",
    "print(\"V = {}\".format(V) )\n",
    "print(\"A = {}\".format(A) )\n",
    "print(\"E = {}\".format(E) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way to read these matrices is that a good corresponds to a row and an agent to a column. For example, agent 1's endowment of good 2, $e^1_2$, would be the element in the second row and first column of matrix **E**, and hence $e^1_2 = 5$.\n",
    "\n",
    "With these parameter values, confirm that your analytical result equals the numerical output of your program. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Test your program for higher numbers of goods and agents. You can create the parameter matrices above using Numpy's **np.random.uniform** function. Can your program handle $m = n = 5$? $m = n = 10$?      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint**: A slightly tricky issue when answering this question using *unconstrained* numerical optimization methods is how to deal with the constraint that aggregate consumption of good $j$ must equal aggregate endowments, i.e.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\sum^{n}_{i = 1} x_j^i = \\sum^{n}_{i = 1} e_j^i\n",
    "\\end{equation}\n",
    "\n",
    "One way to address this is to have the algorithm solve for the optimal consumption for $n - 1$ agents and evaluate the consumption and hence the utility of the last agent *as the residual*. Formally, for good $j$,\n",
    "\n",
    "\\begin{equation}\n",
    "    x_j^n = \\sum^{n}_{i = 1} e_j^i - \\sum^{n-1}_{i = 1} x_j^i\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (N)\n",
    "\n",
    "Consider the neoclassical growth model from the lecture. In this question, we extend it so that the production function contains *energy* $m_t$ as a third production factor in addition to capital and labor. Hence, output is given by\n",
    "\n",
    "\\begin{equation}\n",
    "    y_t = f(k_t, h_{y,t}, m_t) = A k_t^\\alpha m_t^\\gamma h_{y,t}^{1-\\alpha-\\gamma}\n",
    "\\end{equation}\n",
    "\n",
    "Energy is itself produced by using a part of the labor supply:\n",
    "\n",
    "\\begin{equation}\n",
    "    m_t = \\rho h_{m,t}\n",
    "\\end{equation}\n",
    "\n",
    "which implies that one unit of labor supply creates $\\rho$ units of energy.\n",
    "\n",
    "Solve the planner problem numerically for $T = 30$. Note that lifetime utility is still given by \n",
    "\n",
    "\\begin{equation}\n",
    "    u(c_t, h_t) = \\frac{c^{1-\\nu}}{1-\\nu} - B \\frac{h_t^{1+\\eta}}{1+\\eta}\n",
    "\\end{equation}\n",
    "\n",
    "with $h_t = h_{y,t} + h_{m,t}$. You can use the parameter values from the lecture, and $\\gamma = 0.05$ and $\\rho = 0.9$. \n",
    "\n",
    "In addition, compute the steady state using a root finding algorithm and verify that the planner's sequences for $k_t$, $h_{y,t}$ and $h_{m,t}$ converge to their steady state values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (N)\n",
    "\n",
    "In this question, we are going to apply the gradient descent minimization algorithm on a least-squares regression problem. Consider the Bundesliga data set used in the *Introduction to Python* section of this class. Let's assume we would like to regress a player's market value on his age, his number of goals and assists. Running the following cell (i) reads in the relevant columns of the data set; (ii) creates a matrix **X** with the explanatory variables (in logs) and a constant; and (iii) creates an array **y** containing the dependent variables (in logs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 'value')\n",
      "(4, 'age')\n",
      "(5, 'goals')\n",
      "(6, 'assists')\n",
      "(291, 4)\n",
      "(291, 1)\n",
      "[[ 1.          3.36729583  3.4339872   1.60943791]\n",
      " [ 1.          3.33220451  3.40119738  1.09861229]\n",
      " [ 1.          3.33220451  1.79175947  2.56494936]\n",
      " [ 1.          3.33220451  1.79175947  1.60943791]\n",
      " [ 1.          3.29583687  1.60943791  1.38629436]\n",
      " [ 1.          3.04452244  1.94591015  2.48490665]\n",
      " [ 1.          3.29583687  1.09861229  1.09861229]\n",
      " [ 1.          3.36729583  2.39789527  1.09861229]\n",
      " [ 1.          3.04452244  1.09861229  0.69314718]\n",
      " [ 1.          3.04452244  1.09861229  0.69314718]]\n"
     ]
    }
   ],
   "source": [
    "cols=(2,4,5,6)\n",
    "D = np.loadtxt('BundesligaData.txt', delimiter=';',usecols=(cols), skiprows=1)\n",
    "D[:10, :]\n",
    "\n",
    "description = ['name', 'position', 'value', 'valuemax', 'age', 'goals','assists', 'yellow', 'red', 'shotspergame','passsuccess','aerialswon', 'rating', 'positioncode']\n",
    "for i in cols:\n",
    "    print((i,description[i]))\n",
    "    \n",
    "X = np.column_stack((np.ones( D.shape[0] ), np.log( D[:,1:] + 1 )))\n",
    "## dependent variable\n",
    "y = np.log( D[:,0] )\n",
    "y.shape=(D.shape[0], 1)\n",
    "# Before regressing the values, we should check whether X and y have the right shape\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(X[:10, :])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(As a side note: in practice, it would be much more convenient to work with the dataset as a *Pandas dataframe*. Since using Pandas is not required for this course, we use standard Numpy arrays instead.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) For comparison, use the standard formula for the OLS estimator to compute $\\mathbf{b}$.\n",
    "\n",
    "(b) Implement the gradient descent algorithm outlined above to find $\\mathbf{b}$. Assume that the step size $\\alpha$ is constant. You may have to play around with $\\alpha$ to find a value that gives you convergence. *Hint*: Recall that in the context of gradient descent, convergence may be slow. When implementing the algorithm above with a **while** loop, you should (as we always do) include a condition that the loop stops after a certain number of iterations, **maxit**. Make sure to set **maxit** sufficiently high in order to get convergence.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
