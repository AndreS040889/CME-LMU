{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Methods in Economics\n",
    "\n",
    "## Lecture 4 - Root Finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last update: 2017-11-05 18:56:47.660214\n"
     ]
    }
   ],
   "source": [
    "# Author: Alex Schmitt (schmitt@ifo.de)\n",
    "\n",
    "import datetime\n",
    "print('Last update: ' + str(datetime.datetime.today()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn\n",
    "\n",
    "import scipy.optimize\n",
    "\n",
    "# import sys\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Lecture\n",
    "\n",
    "- [Introduction](#introduction)\n",
    "- [Bisection](#bisection)\n",
    "- [Function Iteration](#funiter)\n",
    "- [Newton's Method](#newton)\n",
    "- [Numerical Differentiation](#numdiff)\n",
    "- [Quasi-Newton Methods](#quasi)\n",
    "- [The Scipy Package](#scipy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "<a id = \"introduction\"></a>\n",
    "\n",
    "A function $f(x)$ has a *root* (also called a *zero*) at $x^*$ if $f(x^*) = 0$. Note that $f$ here can be a univariate function (both input and output are scalars, or both its range and its domain have a dimension of 1), a multivariate function (its inputs are vectors, hence its domain has a dimension greater than 1) or vector-valued (both its range and its domain have a dimension greater than 1. In the latter case, finding the roots of a vector-valued function is equivalent to *solving a system of nonlinear equations*. \n",
    "\n",
    "Finding the root(s) of a function is one of the most common computational problems in economics, often applied when looking for an equilibrium. In other words, an equilibrium is usually defined by a set of equations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Neoclassical Growth Model\n",
    "\n",
    "\n",
    "- Utility function:\n",
    "\n",
    "\\begin{equation}\n",
    "    u(c, h) = \\frac{c^{1-\\nu}}{1-\\nu} - B \\frac{h^{1+\\eta}}{1+\\eta}\n",
    "\\end{equation}\n",
    "\n",
    "with $c$ denoting consumption and $h$ labor supply.\n",
    "\n",
    "- Production function:\n",
    "\n",
    "\\begin{equation}\n",
    "    f(k, h) = A k^\\alpha h^{1-\\alpha}\n",
    "\\end{equation}\n",
    "with $k$ denoting the capital stock, and $\\theta$ a productivity shock.\n",
    "\n",
    "- Resource Constraint:\n",
    "\n",
    "\\begin{equation}\n",
    "    k_{t+1} + c_t = f(k_t, h_t) + (1 - \\delta) k_t = A k_t^\\alpha h_t^{1-\\alpha} + (1 - \\delta) k_t\n",
    "\\end{equation}\n",
    "\n",
    "- Planner's Problem:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\max_{\\left\\{c_t, k_{t+1}, h_t\\right\\}} \\sum^\\infty_{t = 0} \\beta^t u(c_t, h_t) \n",
    "\\end{equation}\n",
    "s.t. the resource constraint.\n",
    "\n",
    "- F.o.c's:\n",
    "(1) Euler equation\n",
    "\n",
    "\\begin{equation}\n",
    "    c^{-\\nu} = \\beta \\left[ (c')^{-\\nu} (f_k(k', h') + 1 - \\delta) \\right]    \n",
    "\\end{equation}\n",
    "\n",
    "(2) intratemporal optimality condition\n",
    "\n",
    "\\begin{equation}\n",
    "    B h^{\\eta} = c^{-\\nu} f_h(k, h)  \n",
    "\\end{equation}\n",
    "\n",
    "where I have used the notation $c = c_t$ and $c' = c_{t+1}$ for brevity. \n",
    "\n",
    "In an equilibrium, the two first-order conditions, combined with the resource constraint, must hold in every period. We will get to how to solve for the full dynamic allocation later in this course. For now, let's consider the *steady state*, where all variables are constant over time, i.e. $c_t = c_{t+1} = c_s$ and so on. The Euler equation then can be simplied to:\n",
    "\n",
    "\\begin{equation}\n",
    "    1 = \\beta \\left[f_k(k_s, h_s) + 1 - \\delta \\right]    \n",
    "\\end{equation}\n",
    "\n",
    "For the intratemporal optimality condition, use the resource constraint to substitute consumption:\n",
    "\n",
    "\\begin{equation}\n",
    "    B h_s^{\\eta} = \\left[ f(k_s, h_s) - \\delta k_s \\right]^{-\\nu} f_h(k_s, h_s)  \n",
    "\\end{equation}\n",
    "\n",
    "This is a nonlinear system of two equations, with two unknown variables, $k_s$ and $h_s$, which can be solved using the method introduced below. We can also define a vector-valued function $\\mathbf{S}$ with\n",
    "\n",
    "\\begin{equation}\n",
    "   \\mathbf{S}(k, h) = \n",
    "    \\left[\n",
    "    \\begin{array}{c}\n",
    "        \\beta \\left[f_k(k, h) + 1 - \\delta \\right]  - 1 \\\\\n",
    "        \\left[ f(k, h) - \\delta k \\right]^{-\\nu} f_h(k, h) - B h^{\\eta}\n",
    "    \\end{array}\n",
    "    \\right]\n",
    "\\end{equation}\n",
    "\n",
    "Finding the steady state of the model then requires finding a root of function $\\mathbf{S}$, i.e. a vector $(k_s, h_s)$ such that \n",
    "\n",
    "\\begin{equation}\n",
    "   \\mathbf{S}(k_s, h_s) = \n",
    "    \\left[\n",
    "    \\begin{array}{c}\n",
    "        0 \\\\\n",
    "        0\n",
    "    \\end{array}\n",
    "    \\right]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bisection\n",
    "\n",
    "<a id = 'bisection'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to compute the root of a continuous univariate real-valued function is the *bisection method*. While simple, bisection captures two important features of most root-finding and optimization methods: it is a *local* method and it is based on an *iterative procedure*.\n",
    "\n",
    "The key idea behind the bisection method is based on the *Intermediate Value Theorem*: if $f$ is continuous and defined on the interval $[a,b]$, and if $f(a)$ and $f(b)$ are distinct values, then $f$ must assume all values in between. Since we are interested in where $f$ assumes the value 0, we need $f(a)$ and $f(b)$ to have different signs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bisection method implements the following \"pseudo-code\":\n",
    "\n",
    "(i) Start with two values $a$ and $b$ such that $f(a)$ and $f(b)$ are defined and have different signs. Moreover, specify a \"tolerance level\" $tol$ which should be a very small number, e.g. 1e-8.\n",
    "\n",
    "(ii) Compute the midpoint between $a$ and $b$, $x = \\frac{a + b}{2}$. \n",
    "\n",
    "(iii) If $f(x)$ has the same sign as $f(a)$, replace the left endpoint of the interval with $x$, i.e. $a = x$.\n",
    "\n",
    "(iv) If $f(x)$ has the same sign as $f(b)$, replace the right endpoint of the interval with $x$, i.e. $b = x$.\n",
    "\n",
    "(v) Repeat from (ii) until the absolute value of $f(x)$ is less than $tol$, i.e. $|f(x)| < tol$.\n",
    "\n",
    "Note the following:\n",
    "- Bisection is an *iterative procedure*: at the beginning of each iteration step, the interval $[a,b]$ contains a root of $f$. The interval is then divided (\"bisected\") into two subintervals of equal length. One of the two subintervals must contain the root, and hence have endpoints of different signs. This subinterval is taken as the interval $[a,b]$ used for the next iteration. This process continues until the resulting midpoint $x$ of the current interval is sufficiently close to 0.  \n",
    "- Moreover, bisection is a *local* method: it will not give you all the roots of a function, but only one of the roots (in case there are multiple roots) between $a$ and $b$. A corollary of this is that the outcome of bisection (and of local methods in general) is sensitive to the starting point chosen by the user, here the values for $a$ and $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bisection method is robust in the sense that it will find a root in a known number of iterations, assuming the initial choices for $a$ and $b$ lead to different signs for $f(a)$ and $f(b)$. The obvious downside of bisection is that it only works for univariate functions. Moreover, it is usually slower than the other methods discussed below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this week's problem set, you will be asked to code up the bisection method. Of course, most programming languages already have in-built implementations (e.g. in SciPy: **scipy.optimize.bisect**, as discussed below), so writing your own function may seem a bit redundant, but will help you to get used the inner workings of many of the algorithms used in scientific computing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Iteration\n",
    "<a id = 'funiter'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have started to talk about iterative methods at the end of last lecture. To recap, the basic idea of iterative methods is to generate a sequence of approximations to the object of interest, e.g. the solution to linear or nonlinear system of equations, following an iteration rule: \n",
    "\n",
    "\\begin{equation}\n",
    "    x^{(k+1)} = g( x^{(k)} ),\n",
    "\\end{equation}\n",
    "\n",
    "where $k$ is an indicator counting the number of iterations. Hence, in words, the value for $x$ in the $k+1$-iteration is obtained by applying function $g$ on the value for $x$ in the $k$-iteration. Ideally, these approximations become more and more precise with an increasing number of iterations. Recall that iterative methods, in contrast to direct methods, do not yield an exact solution.\n",
    "\n",
    "\n",
    "When finding the root of a function $f$ or solving for a system of nonlinear equations, the functional form of $g$ is simply\n",
    "\n",
    "\\begin{equation}\n",
    "    g( x ) = x - f(x).\n",
    "\\end{equation}\n",
    "\n",
    "This is intuitive: at the root $ x = x* $, we have $f(x^*) = 0$ and hence $g (x^*) = x^*$. In other words, $x^*$ is a *fixed point*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following piece of code implements function iteration. As a simple workhorse example, consider the function\n",
    "\n",
    "\\begin{equation}\n",
    "    f(x) = 4 \\ln(x) - 4,\n",
    "\\end{equation}\n",
    "\n",
    "which has a root at $x = e^x = 2.718282$. For illustration, we print the current guess for $x^{(k)}$ for each iteration. As we can see,  $x^{(k)}$ converges to $x^*$ as the number of iterations increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fun(x):\n",
    "    return 4*np.log(x) - 4\n",
    "\n",
    "def g(x):\n",
    "    return x - fun(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.45482255552\n",
      "2.86260463623\n",
      "2.65567694682\n",
      "2.74887857583\n",
      "2.70410642422\n",
      "2.72502036232\n",
      "2.71511676033\n",
      "2.7197769279\n",
      "2.71757746733\n",
      "2.71861408156\n",
      "2.7181251951\n",
      "2.71835569051\n",
      "2.71824700267\n",
      "2.71829824977\n",
      "2.71827408559\n",
      "2.71828547937\n",
      "2.71828010699\n",
      "2.71828264016\n",
      "2.71828144573\n",
      "2.71828200892\n",
      "2.71828174337\n",
      "2.71828186858\n",
      "2.71828180954\n",
      "2.71828183738\n",
      "2.71828182425\n",
      "Number of iterations = 25\n"
     ]
    }
   ],
   "source": [
    "tol = 1e-8\n",
    "x = 4\n",
    "it = 0\n",
    "lst = []\n",
    "while abs((x - g(x))) > tol:\n",
    "    it += 1\n",
    "    x = g(x)\n",
    "    lst.append(x)\n",
    "    print(x)\n",
    "    \n",
    "\n",
    "print(\"Number of iterations = {}\".format(it) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11febe0f0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFJCAYAAADaPycGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1122e0208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(0.9, 3, 100)\n",
    "fig, ax = plt.subplots(2,1)\n",
    "# ax[0].ylabel($$f(x)$$)\n",
    "ax[0].plot(x, fun(x))\n",
    "ax[0].hlines(0, 0, 3)\n",
    "ax[1].plot(x, g(x))\n",
    "ax[1].plot(x, x, '--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton's Method\n",
    "<a id = 'newton'></a>\n",
    "\n",
    "\n",
    "Most algorithms used in practice to find the roots of a nonlinear system of equations are based on Newton's method. As function iteration, it is an iterative method. However, it uses additional information, namely about the derivatives of $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate Function\n",
    "\n",
    "Let us start with the case of a univariate function $f$. Recall that we want to find a root $x^*$ of the function $f$, i.e. where $f(x^*) = 0$. Start with an initial guess for $x^*$, denoted by $x_0$. We can approximate $f$ with a first-order Taylor approximation around $x_0$:\n",
    "\n",
    "\\begin{equation}\n",
    "    f(x) \\approx f(x_0) + (x - x_0) f'(x_0)\n",
    "\\end{equation}\n",
    "\n",
    "Setting $f(x) = 0$ - our target value - and solving this expression for $x$ gives us the \"best guess\" for $x^*$ given the initial guess and the properties of the function (i.e. its value and derivative) at $x_0$:\n",
    "\\begin{equation}\n",
    " x_1 \\approx x_0 - \\frac{f(x_0)}{f'(x_0)}\n",
    "\\end{equation}\n",
    "\n",
    "Iterating on this step, we can again generate a sequence $x_1, x_2, ..., x_n$; hence the iteration rule is given by:\n",
    "\n",
    "\\begin{equation}\n",
    " x^{(k+1)} = x^{(k)} - \\frac{f(x^{(k)})}{f'(x^{(k)})}\n",
    "\\end{equation}\n",
    "\n",
    "In other words, the functional form of $g$ is now\n",
    "\\begin{equation}\n",
    "    g( x ) = x - \\frac{f(x)}{f'(x)}.\n",
    "\\end{equation}\n",
    "\n",
    "Comparing to simple function iteration above, we have one additional term, the derivative of $f$ at $x^{(k)}$. Hence, we use more information on the properties of the function than above. More precisely, we put a weight on the distance between the old guess $x^{(k)}$ and the new guess $x^{(k+1)}$. With function iteration, the distance was given by $f(x^{(k)})$, while in Newton's method, it is $f(x^{(k)})/f'(x^{(k)})$. It is intuitive why this is an improvement:\n",
    "- if the absolute value of $f'(x^{(k)})$ is small, this means the function is relatively flat; in this case, it is likely that the current guess $x^{(k)}$ is still far from the root, and hence the jump to the next guess should be large\n",
    "- if the absolute value of $f'(x^{(k)})$ is large, the function is relatively steep, making it more likely that we are close to  the root; hence the jump to the next guess should be small\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code implements Newton's method. As before, the current guess for $x$ is printed in every iteration. Unsurprisingly given the intuition above, Newton's method needs considerably fewer iterations than simple function iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "2.61370563888\n",
      "2.71624392636\n",
      "2.71828106436\n",
      "2.71828182846\n",
      "2.71828182846\n",
      "Number of iterations = 6\n"
     ]
    }
   ],
   "source": [
    "def fd(x):\n",
    "    return 4/x\n",
    "\n",
    "def g_newton(fun, fun_d, x):\n",
    "    f, fd = fun(x), fun_d(x)\n",
    "    return x - f * fd**(-1)\n",
    "\n",
    "def my_newton(fun, fun_d, x):\n",
    "    \n",
    "    eps = 1\n",
    "    tol = 1e-8\n",
    "    it = 0\n",
    "    \n",
    "    while eps > tol:\n",
    "        it += 1\n",
    "        x_new = g_newton(fun, fun_d, x)\n",
    "        eps = abs(x - x_new)\n",
    "        x = x_new\n",
    "        print(x_new)\n",
    "    \n",
    "    print(\"Number of iterations = {}\".format(it) )\n",
    "    \n",
    "    return x\n",
    "        \n",
    "x_root = my_newton(fun, fd, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multivariate Case\n",
    "\n",
    "The logic from the univariate case translates to a vector-valued function.\n",
    "\n",
    "Let $\\mathbf{x}$ be a n-by-1 vector and $\\mathbf{f}$ be a multivariate function. Define its Jacobian as\n",
    "\n",
    "\\begin{equation}\n",
    " J(\\mathbf{x}) = \\left[\n",
    "\\begin{matrix}\n",
    " \\partial f_1/ \\partial x_1 & ... & \\partial f_1/ \\partial x_n \\\\\n",
    " \\vdots & \\ddots & \\vdots \\\\\n",
    "  \\partial f_n/ \\partial x_1 & ... & \\partial f_n/ \\partial x_n \n",
    "\\end{matrix}  \\right]\n",
    "\\end{equation}\n",
    "\n",
    "Start with a first-order Taylor approximation around $\\mathbf{x}_0$:\n",
    "\\begin{equation}\n",
    " 0 = \\mathbf{f}(\\mathbf{x}) \\approx \\mathbf{f}(\\mathbf{x}_0) + J(\\mathbf{x}) (\\mathbf{x} - \\mathbf{x}_0)\n",
    "\\end{equation}\n",
    "Hence,\n",
    "\\begin{equation}\n",
    " \\mathbf{x} \\approx \\mathbf{x}_0 - J^{-1}(\\mathbf{x}_0) f(\\mathbf{x}_0)\n",
    "\\end{equation}\n",
    "\n",
    "The key idea is to use this relation iteratively, i.e. generate a sequence $\\mathbf{x}_1, \\mathbf{x}_2, ..., \\mathbf{x}_m$ where\n",
    "\n",
    "\\begin{equation}\n",
    " \\mathbf{x}_{k+1} \\approx \\mathbf{x}_{k} - J^{-1}(\\mathbf{x}_{k}) f(\\mathbf{x}_{k})\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1911455  1.       ]\n",
      "Number of iterations = 6\n",
      "[ 0.1911455  1.       ]\n"
     ]
    }
   ],
   "source": [
    "def foc(x):\n",
    "    \"\"\"\n",
    "    Implements a system of equation in two unknowns, here an optimality condition for a production problem\n",
    "    where x[0] has marginal cost phi and x[1] is in limited supply\n",
    "    \"\"\"\n",
    "    alpha = 0.33\n",
    "    phi = 1\n",
    "\n",
    "    return (alpha* x[0]**(alpha - 1) * x[1]**(1 - alpha) - phi, x[1] - 1)\n",
    "\n",
    "\n",
    "def foc_J(x):\n",
    "    \"\"\"\n",
    "    Implements the Jacobian system of equation in two unknowns\n",
    "    \"\"\"\n",
    "    alpha = 0.33\n",
    "    phi = 1\n",
    "\n",
    "    f_00 = alpha * (alpha - 1) * x[0]**(alpha - 2) * x[1]**(1 - alpha)\n",
    "    f_01 = alpha * (1 - alpha) * x[0]**(alpha - 1) * x[1]**(- alpha)\n",
    "    f_10 = 0\n",
    "    f_11 = 1\n",
    "    \n",
    "    return np.array([[f_00, f_01], [f_10, f_11]])   \n",
    "\n",
    "\n",
    "def my_newton_mult(fun, fun_d, x):\n",
    "    eps = 1\n",
    "    tol = 1e-8\n",
    "    it = 0\n",
    "    while eps > tol:\n",
    "        it += 1\n",
    "        f, J = fun(x), fun_d(x)\n",
    "        x_new = x - np.linalg.inv(J) @ f\n",
    "        eps = np.linalg.norm(x - x_new)\n",
    "        x = x_new\n",
    "    \n",
    "    print(\"Number of iterations = {}\".format(it) )\n",
    "    \n",
    "    return x\n",
    "        \n",
    "x_init = [0.3,1]\n",
    "print(scipy.optimize.fsolve(foc, x_init))\n",
    "print(my_newton_mult(foc, foc_J, x_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Differentation\n",
    "\n",
    "<a id = \"numdiff\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, it is useful to look at *numerical differentiation*: instead of working with precise derivatives of a function, we can use numerical approximations for these derivatives. Both in the case of a (uni- or multivariate) scalar function and a vector-valued functions, numerical derivatives are based on the *secant*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## cp. classroom notes: derivation of the secant\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scipy has a function **scipy.optimize.approx_fprime** that finds this difference quotient both for univariate and multivariate scalar functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1428571428571428"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## precise derivative of the example function below\n",
    "fd(3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.14284082])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## numerical derivative\n",
    "scipy.optimize.approx_fprime([3.5], fun, [1e-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the multidimensional case, a numerical approximation $A$ of the Jacobian should satisfy the *secant condition*:\n",
    "\n",
    "\\begin{equation}\n",
    " \\mathbf{f}(\\mathbf{x}_1) - \\mathbf{f}(\\mathbf{x}_0) = A^{-1} (\\mathbf{x}_1 - \\mathbf{x}_0)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quasi-Newton Methods\n",
    "<a id = 'quasi'></a>\n",
    "\n",
    "\n",
    "There is an obvious cost of using Newton's method as outlined above: we need to provide the analytical derivative of a univariate scalar function or the Jacobian of a vector-valued function, respectively. While this may be not a big deal for simple functions as in the examples above, for more complicated problems, this step may involve a large computational cost in the best case, and be outright impossible in the worst case. Moreover, coding up complicated derivatives increases the risk of mistakes (\"bugs\") by the programmer.\n",
    "\n",
    "Hence, in practice we often rely on \"derivative-free\" or *Quasi-Newton* methods. In a nutshell, their basic idea is the same as in Newton method's, but instead of using the precise derivatives of a function, we approximate them numerically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.04920587]\n",
      "[ 2.6422194]\n",
      "[ 2.71861783]\n",
      "[ 2.71827566]\n",
      "[ 2.71828194]\n",
      "[ 2.71828183]\n",
      "[ 2.71828183]\n",
      "Number of iterations = 7\n"
     ]
    }
   ],
   "source": [
    "def g_secant(fun, fun_d, x):\n",
    "    f, fd = fun(x), scipy.optimize.approx_fprime([x], fun, [1e-1])\n",
    "    return x - f * fd**(-1)\n",
    "\n",
    "def my_secant(fun, fun_d, x):\n",
    "    \n",
    "    eps = 1\n",
    "    tol = 1e-8\n",
    "    it = 0\n",
    "    \n",
    "    while eps > tol:\n",
    "        it += 1\n",
    "        x_new = g_secant(fun, fun_d, x)\n",
    "        eps = abs(x - x_new)\n",
    "        x = x_new\n",
    "        print(x_new)\n",
    "    \n",
    "    print(\"Number of iterations = {}\".format(it) )\n",
    "    \n",
    "    return x\n",
    "\n",
    "x_root = my_secant(fun, fd, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Scipy Package\n",
    "<a id = 'scipy'></a>\n",
    "\n",
    "Modern programming languages have built-in implementations of the algorithms outlined above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One dimension\n",
    "\n",
    "For the univariate case, consider again the function \n",
    "\n",
    "\\begin{equation}\n",
    "    f(x) = 4 \\ln(x) - 4\n",
    "\\end{equation}\n",
    "\n",
    "To find it numerically, the first thing we need to do is to import Scipy's subpackage *optimize*. We then define the function and use the **bisect()** function, an implementation of the bisection method outlined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.718281828459567\n"
     ]
    }
   ],
   "source": [
    "def fun(x):\n",
    "    return 4*np.log(x) - 4\n",
    "\n",
    "print(scipy.optimize.bisect(fun,1,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**bisect(fun,a,b)** takes three arguments: the function, and an upper and lower initial guess for the root. In other words, you tell the algorithm to look for a root in the interval $[a,b]$. The important thing to note here is that $f(a)$ and $f(b)$ must have different signs - if they do not, you will get an error message (in this case, change $a$ or $b$ and try again).  \n",
    "\n",
    "In the example above, solving for the root using Python is not really necessary. The real advantage of numerical root finding is in situations where finding a solution to $f(x) = 0$ analytically is not feasible. Consider, for example,\n",
    "\n",
    "\\begin{equation}\n",
    "    f(x) = \\sin(4 (x - 1/4)) + x + x^{20} - 1\n",
    "\\end{equation}\n",
    "\n",
    "Finding a root via the bisection method is straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4082935042806639\n"
     ]
    }
   ],
   "source": [
    "def fun(x):\n",
    "    return np.sin(4 * (x - 0.25)) + x + x**20 - 1\n",
    "\n",
    "print(scipy.optimize.bisect(fun,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %timeit scipy.optimize.bisect(fun,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %timeit scipy.optimize.fsolve(fun,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %timeit scipy.optimize.fsolve(f,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %timeit scipy.optimize.root(fun,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Dimensions: NGM Revisited\n",
    "\n",
    "As an example for multidimensional system of nonlinear equation, let's go back to our NGM model. Recall that a steady state is given by $(k_s, h_s)$ such that\n",
    "\n",
    "\\begin{equation}\n",
    "    \\left[\n",
    "    \\begin{array}{c}\n",
    "        S_1 \\\\\n",
    "        S_2\n",
    "    \\end{array}\n",
    "    \\right] =    \n",
    "    \\left[\n",
    "    \\begin{array}{c}\n",
    "        \\beta \\left[f_k(k_s, h_s) + 1 - \\delta \\right]  - 1 \\\\\n",
    "        \\left[ f(k_s, h_s) - \\delta k \\right]^{-\\nu} f_h(k_s, h_s) - B h_s^{\\eta}\n",
    "    \\end{array}\n",
    "    \\right] = \n",
    "    \\left[\n",
    "    \\begin{array}{c}\n",
    "        0 \\\\\n",
    "        0\n",
    "    \\end{array}\n",
    "    \\right]\n",
    "\\end{equation}\n",
    "\n",
    "For solving this system numerically, we first need to assign values to the model parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## utility\n",
    "beta = 0.8      # discount factor\n",
    "nu = 2       # risk-aversion coefficient for consumption\n",
    "eta = 1         # elasticity parameter for labor supply\n",
    "eps = 1e-6      # lower bound of consumption and labor supply\n",
    "## production\n",
    "alpha = 0.25\n",
    "delta = 0\n",
    "## derived\n",
    "# A = (1 - beta * (1 - delta))/(alpha*beta) # normalization parameter for production function => steady state k = 1\n",
    "# B = (1 - alpha) * A * (A - delta)**nu      # parameter for utility function\n",
    "B = 0.8\n",
    "A = 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions\n",
    "\n",
    "Next, it will be useful to define some auxiliary functions that implement the Cobb-Douglas production function, as well as its first and second derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cobb_douglas(x, alpha, A):\n",
    "    \"\"\"\n",
    "    Evaluates the Cobb-Douglas function with coefficient alpha and shift parameter A, for two inputs (x)\n",
    "    \"\"\"\n",
    "    return A * x[0]**alpha * x[1]**(1 - alpha)\n",
    "\n",
    "def cd_diff(x, alpha, A):\n",
    "    \"\"\"\n",
    "    Evaluates the first derivatives (returned as a tuple) of the Cobb-Douglas function with coefficient alpha and shift parameter A, for two inputs (x)\n",
    "    \"\"\"\n",
    "    return (A * alpha * cobb_douglas(x, alpha, A) / x[0], A * (1 - alpha) * cobb_douglas(x, alpha, A) / x[1])\n",
    "\n",
    "def cd_diff2(x, alpha, A):\n",
    "    \"\"\"\n",
    "    Evaluates the second derivative (returned as a tuple, with the cross derivative as the last element) of the Cobb-Douglas function with coefficient alpha and shift parameter A, for two inputs (x)\n",
    "    \"\"\"\n",
    "    return (A * alpha * (alpha - 1) * cobb_douglas(x, alpha, A) / x[0]**2, \n",
    "            A * (1 - alpha) * (-alpha) * cobb_douglas(x, alpha, A) / x[1]**2,\n",
    "            A * alpha * (1 - alpha) * cobb_douglas(x, alpha, A) / (x[0] * x[1]) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can code up the system of nonlinear equations $S$ as a Numpy array. For Newton's method, we also need to provide the Jacobian, i.e.\n",
    "\n",
    "\\begin{equation}\n",
    " J(k, h) = \\left[\n",
    "\\begin{matrix}\n",
    " \\partial S_1/ \\partial k &  \\partial S_1/ \\partial h \\\\\n",
    "  \\partial S_2/ \\partial k &  \\partial S_2 / \\partial h \n",
    "\\end{matrix}  \\right]\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def steady(x):\n",
    "    \"\"\"\n",
    "    Returns the vector-valued function consisting of the steady-state conditions \n",
    "    \"\"\"\n",
    "    y = np.zeros(2)\n",
    "    mp = cd_diff(x, alpha, A)\n",
    "    \n",
    "    y[0] = beta * (mp[0] + 1 - delta) - 1\n",
    "    y[1] = (cobb_douglas(x, alpha, A) - delta * x[0])**(-nu) * mp[1] - B * x[1]**eta\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "def steady_jac(x):\n",
    "    \"\"\"\n",
    "    Returns the Jacobian of the vector-valued function consisting of the steady-state conditions \n",
    "    \"\"\"\n",
    "    J = np.zeros((2,2))\n",
    "    mp = cd_diff(x, alpha, A)\n",
    "    mp2 = cd_diff2(x, alpha, A)\n",
    "    \n",
    "    Q = cobb_douglas(x, alpha, A) - delta * x[0]\n",
    "    \n",
    "    J[0,0] = beta * mp2[0] \n",
    "    J[0,1] = beta * mp2[2]\n",
    "    J[1,1] = -nu * Q**(-nu-1) * mp[1]**2 + Q**(-nu) * mp2[1] - B * eta * x[1]**(eta - 1)\n",
    "    J[1,0] = -nu * Q**(-nu-1) * mp[1] * (mp[0] - delta) + Q**(-nu) * mp2[2] \n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solve for the steady state\n",
    "\n",
    "Start by using our implementation of Newton's method written above. We also need to provide an initial guess $x0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations = 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.23548993,  0.95820563])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = np.array([0.5, 0.5])\n",
    "my_newton_mult(steady, steady_jac, x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I use Scipy's **optimize.broyden1** function, an implementation of Broyden's method outlined above. As it is derivative-free, we do not have to provide the Jacobian: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.23548994  0.95820563]\n"
     ]
    }
   ],
   "source": [
    "res = scipy.optimize.broyden1(steady, x0, f_tol = 1e-8)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that alternatively, you can also call Scipy's **optimize.root** function, which is essentially a \"wrapper\" around different algorithms for solving nonlinear systems of equations, not only Broyden's method. I usually use the **root** function since it provides a more informative output, in particular on function values and number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: array([  7.35234096e-12,  -1.00914832e-11])\n",
      " message: 'A solution was found at the specified tolerance.'\n",
      "     nit: 20\n",
      "  status: 1\n",
      " success: True\n",
      "       x: array([ 1.23548993,  0.95820563])\n"
     ]
    }
   ],
   "source": [
    "res = scipy.optimize.root(steady, x0,  tol = 1e-8, method = \"broyden1\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, Broyden's method takes more iterations to solve the system than Newton's method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
